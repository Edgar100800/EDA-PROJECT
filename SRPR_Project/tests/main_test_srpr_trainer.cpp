#include "../include/SRPR_Trainer.h"
#include "../include/UserItemStore.h"
#include "../include/Triplet.h"
#include <iostream>
#include <vector>
#include <set>
#include <chrono>
#include <cmath>
#include <algorithm>

// Funci√≥n para generar tripletas de prueba sint√©ticas
std::vector<Triplet> generate_synthetic_triplets(int num_users, int num_items, int triplets_per_user) {
    std::vector<Triplet> triplets;
    
    for (int user = 1; user <= num_users; ++user) {
        for (int t = 0; t < triplets_per_user; ++t) {
            int preferred = (user * 10 + t) % num_items + 1;
            int less_preferred = (user * 15 + t + 5) % num_items + 1;
            
            // Asegurar que preferred != less_preferred
            if (preferred == less_preferred) {
                less_preferred = (less_preferred % num_items) + 1;
            }
            
            triplets.push_back({user, preferred, less_preferred});
        }
    }
    
    return triplets;
}

// Funci√≥n para calcular m√©tricas de evaluaci√≥n
double calculate_preference_accuracy(const std::vector<Triplet>& test_triplets, 
                                   const UserItemStore& store) {
    int correct_predictions = 0;
    
    for (const auto& triplet : test_triplets) {
        try {
            const Vector& user_vec = store.get_user_vector(triplet.user_id);
            const Vector& preferred_vec = store.get_item_vector(triplet.preferred_item_id);
            const Vector& less_preferred_vec = store.get_item_vector(triplet.less_preferred_item_id);
            
            // Calcular similitudes (producto punto)
            double sim_preferred = 0.0, sim_less_preferred = 0.0;
            for (size_t i = 0; i < user_vec.size(); ++i) {
                sim_preferred += user_vec[i] * preferred_vec[i];
                sim_less_preferred += user_vec[i] * less_preferred_vec[i];
            }
            
            // Verificar si la predicci√≥n es correcta
            if (sim_preferred > sim_less_preferred) {
                correct_predictions++;
            }
        } catch (const std::exception& e) {
            // Ignorar tripletas con vectores no encontrados
            continue;
        }
    }
    
    return (double)correct_predictions / test_triplets.size();
}

int main() {
    std::cout << "=== Prueba Completa de SRPR_Trainer ===" << std::endl;
    
    auto start_time = std::chrono::high_resolution_clock::now();
    
    // === CONFIGURACI√ìN DE LA PRUEBA ===
    int dimensions = 16;  // Dimensiones m√°s peque√±as para pruebas r√°pidas
    int num_users = 20;
    int num_items = 50;
    int triplets_per_user = 10;
    
    std::cout << "\nConfiguraci√≥n de la prueba:" << std::endl;
    std::cout << "  - Dimensiones: " << dimensions << std::endl;
    std::cout << "  - Usuarios: " << num_users << std::endl;
    std::cout << "  - Items: " << num_items << std::endl;
    std::cout << "  - Tripletas por usuario: " << triplets_per_user << std::endl;
    
    // === PASO 1: Generar datos sint√©ticos ===
    std::cout << "\n--- Paso 1: Generando datos sint√©ticos ---" << std::endl;
    
    std::vector<Triplet> all_triplets = generate_synthetic_triplets(num_users, num_items, triplets_per_user);
    
    // Dividir en entrenamiento y validaci√≥n (80/20)
    int split_point = all_triplets.size() * 0.8;
    std::vector<Triplet> training_triplets(all_triplets.begin(), all_triplets.begin() + split_point);
    std::vector<Triplet> validation_triplets(all_triplets.begin() + split_point, all_triplets.end());
    
    std::cout << "‚úì Generadas " << all_triplets.size() << " tripletas sint√©ticas" << std::endl;
    std::cout << "‚úì Entrenamiento: " << training_triplets.size() << " tripletas" << std::endl;
    std::cout << "‚úì Validaci√≥n: " << validation_triplets.size() << " tripletas" << std::endl;
    
    // === PASO 2: Inicializar UserItemStore ===
    std::cout << "\n--- Paso 2: Inicializando UserItemStore ---" << std::endl;
    
    UserItemStore store(dimensions);
    store.initialize(all_triplets);
    store.print_summary();
    
    // === PASO 3: Crear SRPR_Trainer ===
    std::cout << "\n--- Paso 3: Inicializando SRPR_Trainer ---" << std::endl;
    
    SRPR_Trainer trainer(store);
    std::cout << "‚úì SRPR_Trainer creado" << std::endl;
    
    // === PASO 4: Evaluaci√≥n inicial (baseline) ===
    std::cout << "\n--- Paso 4: Evaluaci√≥n inicial (baseline) ---" << std::endl;
    
    double initial_accuracy = calculate_preference_accuracy(validation_triplets, store);
    std::cout << "‚úì Precisi√≥n inicial: " << std::fixed << std::setprecision(4) 
              << (initial_accuracy * 100) << "%" << std::endl;
    
    // Calcular p√©rdida inicial
    SRPR_Trainer::TrainingParams eval_params;
    eval_params.b_lsh_length = 16;
    double initial_loss = trainer.calculate_total_loss(training_triplets, eval_params);
    std::cout << "‚úì P√©rdida inicial: " << std::fixed << std::setprecision(6) << initial_loss << std::endl;
    
    // === PASO 5: Prueba de gradientes ===
    std::cout << "\n--- Paso 5: Verificando c√°lculo de gradientes ---" << std::endl;
    
    // Tomar una muestra peque√±a para verificar gradientes
    std::vector<Triplet> gradient_sample(training_triplets.begin(), 
                                       training_triplets.begin() + std::min(10, (int)training_triplets.size()));
    
    std::vector<double> gradient_norms = trainer.get_gradient_norms(gradient_sample, eval_params);
    
    if (gradient_norms.empty()) {
        std::cout << "‚ùå Error: No se pudieron calcular gradientes" << std::endl;
        return 1;
    }
    
    double avg_gradient_norm = 0.0;
    for (double norm : gradient_norms) {
        avg_gradient_norm += norm;
    }
    avg_gradient_norm /= gradient_norms.size();
    
    std::cout << "‚úì Gradientes calculados para " << gradient_sample.size() << " tripletas" << std::endl;
    std::cout << "‚úì Norma promedio de gradientes: " << std::fixed << std::setprecision(6) 
              << avg_gradient_norm << std::endl;
    
    if (avg_gradient_norm < 1e-10) {
        std::cout << "‚ö†Ô∏è ADVERTENCIA: Gradientes muy peque√±os, posible problema num√©rico" << std::endl;
    } else if (avg_gradient_norm > 100.0) {
        std::cout << "‚ö†Ô∏è ADVERTENCIA: Gradientes muy grandes, considerar reducir learning rate" << std::endl;
    } else {
        std::cout << "‚úì Magnitud de gradientes parece razonable" << std::endl;
    }
    
    // === PASO 6: Entrenamiento con configuraci√≥n b√°sica ===
    std::cout << "\n--- Paso 6: Entrenamiento b√°sico ---" << std::endl;
    
    SRPR_Trainer::TrainingParams basic_params;
    basic_params.epochs = 5;
    basic_params.learning_rate = 0.001;  // Learning rate conservador
    basic_params.b_lsh_length = 16;
    basic_params.regularization = 0.0001;
    basic_params.verbose = true;
    basic_params.validation_freq = 2;
    
    auto training_stats = trainer.train(training_triplets, basic_params, validation_triplets);
    
    // === PASO 7: Evaluaci√≥n post-entrenamiento ===
    std::cout << "\n--- Paso 7: Evaluaci√≥n post-entrenamiento ---" << std::endl;
    
    double final_accuracy = calculate_preference_accuracy(validation_triplets, store);
    double accuracy_improvement = final_accuracy - initial_accuracy;
    
    std::cout << "‚úì Precisi√≥n final: " << std::fixed << std::setprecision(4) 
              << (final_accuracy * 100) << "%" << std::endl;
    std::cout << "‚úì Mejora en precisi√≥n: " << std::fixed << std::setprecision(4) 
              << (accuracy_improvement * 100) << " puntos porcentuales" << std::endl;
    
    double final_loss = trainer.calculate_total_loss(training_triplets, basic_params);
    double loss_improvement = initial_loss - final_loss;
    
    std::cout << "‚úì P√©rdida final: " << std::fixed << std::setprecision(6) << final_loss << std::endl;
    std::cout << "‚úì Mejora en p√©rdida: " << std::fixed << std::setprecision(6) << loss_improvement << std::endl;
    
    // === PASO 8: Prueba con datos reales (si est√°n disponibles) ===
    std::cout << "\n--- Paso 8: Prueba con datos reales ---" << std::endl;
    
    std::vector<Triplet> real_triplets = load_triplets("data/training_triplets.csv");
    
    if (!real_triplets.empty()) {
        std::cout << "‚úì Cargadas " << real_triplets.size() << " tripletas reales" << std::endl;
        
        // Tomar una muestra para entrenamiento r√°pido
        int real_sample_size = std::min(200, (int)real_triplets.size());
        std::vector<Triplet> real_sample(real_triplets.begin(), 
                                       real_triplets.begin() + real_sample_size);
        
        UserItemStore real_store(dimensions);
        real_store.initialize(real_sample);
        
        SRPR_Trainer real_trainer(real_store);
        
        SRPR_Trainer::TrainingParams real_params;
        real_params.epochs = 3;
        real_params.learning_rate = 0.0005;
        real_params.b_lsh_length = 16;
        real_params.regularization = 0.001;
        real_params.verbose = false;  // Menos verboso para datos reales
        
        std::cout << "  Entrenando con muestra de " << real_sample_size << " tripletas..." << std::endl;
        
        auto real_start = std::chrono::high_resolution_clock::now();
        auto real_stats = real_trainer.train(real_sample, real_params);
        auto real_end = std::chrono::high_resolution_clock::now();
        auto real_duration = std::chrono::duration_cast<std::chrono::milliseconds>(real_end - real_start);
        
        std::cout << "‚úì Entrenamiento completado en " << real_duration.count() << " ms" << std::endl;
        std::cout << "‚úì P√©rdida final con datos reales: " << std::fixed << std::setprecision(6) 
                  << real_stats.final_loss << std::endl;
        
    } else {
        std::cout << "‚ö†Ô∏è No se encontraron datos reales, saltando esta prueba" << std::endl;
        std::cout << "  (Ejecuta generate_training_data para crear datos reales)" << std::endl;
    }
    
    // === PASO 9: Pruebas de diferentes configuraciones ===
    std::cout << "\n--- Paso 9: Probando diferentes configuraciones ---" << std::endl;
    
    struct ConfigTest {
        std::string name;
        SRPR_Trainer::TrainingParams params;
    };
    
    std::vector<ConfigTest> configs;
    
    ConfigTest config1;
    config1.name = "Learning Rate Alto";
    config1.params.epochs = 3;
    config1.params.learning_rate = 0.01;
    config1.params.b_lsh_length = 16;
    config1.params.regularization = 0.0001;
    config1.params.verbose = false;
    config1.params.validation_freq = 1;
    
    ConfigTest config2;
    config2.name = "Learning Rate Bajo";
    config2.params.epochs = 3;
    config2.params.learning_rate = 0.0001;
    config2.params.b_lsh_length = 16;
    config2.params.regularization = 0.0001;
    config2.params.verbose = false;
    config2.params.validation_freq = 1;
    
    ConfigTest config3;
    config3.name = "Regularizaci√≥n Alta";
    config3.params.epochs = 3;
    config3.params.learning_rate = 0.001;
    config3.params.b_lsh_length = 16;
    config3.params.regularization = 0.01;
    config3.params.verbose = false;
    config3.params.validation_freq = 1;
    
    ConfigTest config4;
    config4.name = "LSH 8 bits";
    config4.params.epochs = 3;
    config4.params.learning_rate = 0.001;
    config4.params.b_lsh_length = 8;
    config4.params.regularization = 0.0001;
    config4.params.verbose = false;
    config4.params.validation_freq = 1;
    
    ConfigTest config5;
    config5.name = "LSH 32 bits";
    config5.params.epochs = 3;
    config5.params.learning_rate = 0.001;
    config5.params.b_lsh_length = 32;
    config5.params.regularization = 0.0001;
    config5.params.verbose = false;
    config5.params.validation_freq = 1;
    
    configs.push_back(config1);
    configs.push_back(config2);
    configs.push_back(config3);
    configs.push_back(config4);
    configs.push_back(config5);
    
    std::cout << "Comparando configuraciones:" << std::endl;
    std::cout << "  Configuraci√≥n          | P√©rdida Final | Tiempo (ms)" << std::endl;
    std::cout << "  ----------------------|---------------|-------------" << std::endl;
    
    for (const auto& config : configs) {
        // Reinicializar store para cada configuraci√≥n
        UserItemStore config_store(dimensions);
        config_store.initialize(training_triplets);
        
        SRPR_Trainer config_trainer(config_store);
        
        auto config_start = std::chrono::high_resolution_clock::now();
        auto config_stats = config_trainer.train(training_triplets, config.params);
        auto config_end = std::chrono::high_resolution_clock::now();
        auto config_duration = std::chrono::duration_cast<std::chrono::milliseconds>(config_end - config_start);
        
        std::cout << "  " << std::setw(22) << config.name
                  << "| " << std::setw(13) << std::fixed << std::setprecision(6) << config_stats.final_loss
                  << " | " << std::setw(11) << config_duration.count() << std::endl;
    }
    
    // === PASO 10: An√°lisis de convergencia ===
    std::cout << "\n--- Paso 10: An√°lisis de convergencia ---" << std::endl;
    
    if (training_stats.epoch_losses.size() >= 2) {
        std::cout << "Evoluci√≥n de la p√©rdida por epoch:" << std::endl;
        for (size_t i = 0; i < training_stats.epoch_losses.size(); ++i) {
            std::cout << "  Epoch " << (i + 1) << ": " 
                      << std::fixed << std::setprecision(6) << training_stats.epoch_losses[i];
            if (i > 0) {
                double change = training_stats.epoch_losses[i] - training_stats.epoch_losses[i-1];
                std::cout << " (cambio: " << std::fixed << std::setprecision(6) << change << ")";
            }
            std::cout << std::endl;
        }
        
        if (training_stats.converged) {
            std::cout << "‚úì El algoritmo convergi√≥" << std::endl;
        } else {
            std::cout << "‚ö†Ô∏è El algoritmo no convergi√≥ en " << basic_params.epochs << " epochs" << std::endl;
        }
    }
    
    // === RESUMEN FINAL ===
    auto end_time = std::chrono::high_resolution_clock::now();
    auto total_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
    
    std::cout << "\n=== RESUMEN FINAL ===" << std::endl;
    std::cout << "üéâ ¬°Todas las pruebas de SRPR_Trainer completadas!" << std::endl;
    std::cout << "‚è±Ô∏è  Tiempo total de pruebas: " << total_duration.count() << " ms" << std::endl;
    
    std::cout << "\nüìä Resultados principales:" << std::endl;
    std::cout << "   - Mejora en precisi√≥n: " << std::fixed << std::setprecision(2) 
              << (accuracy_improvement * 100) << " puntos porcentuales" << std::endl;
    std::cout << "   - Mejora en p√©rdida: " << std::fixed << std::setprecision(6) << loss_improvement << std::endl;
    std::cout << "   - Velocidad entrenamiento: " << training_stats.total_updates * 1000.0 / training_stats.training_time_ms 
              << " actualizaciones/s" << std::endl;
    std::cout << "   - Convergencia: " << (training_stats.converged ? "S√≠" : "No") << std::endl;
    
    std::cout << "\n‚úÖ Funcionalidades verificadas:" << std::endl;
    std::cout << "   ‚úì Inicializaci√≥n correcta del trainer" << std::endl;
    std::cout << "   ‚úì C√°lculo de gradientes funcional" << std::endl;
    std::cout << "   ‚úì Actualizaci√≥n de vectores" << std::endl;
    std::cout << "   ‚úì Funci√≥n de p√©rdida implementada" << std::endl;
    std::cout << "   ‚úì Entrenamiento con datos sint√©ticos" << std::endl;
    std::cout << "   ‚úì Entrenamiento con datos reales" << std::endl;
    std::cout << "   ‚úì Evaluaci√≥n y m√©tricas" << std::endl;
    std::cout << "   ‚úì Diferentes configuraciones probadas" << std::endl;
    std::cout << "   ‚úì An√°lisis de convergencia" << std::endl;
    
    // Verificar si el entrenamiento fue exitoso
    if (accuracy_improvement > 0.01 || loss_improvement > 0.01) {
        std::cout << "\nüöÄ ¬°SRPR_Trainer funciona correctamente y mejora el modelo!" << std::endl;
        std::cout << "‚úÖ Sistema listo para el pipeline completo!" << std::endl;
        return 0;
    } else {
        std::cout << "\n‚ö†Ô∏è El entrenamiento no mostr√≥ mejoras significativas." << std::endl;
        std::cout << "   Esto puede ser normal con datos sint√©ticos simples." << std::endl;
        std::cout << "‚úÖ Funcionalidad b√°sica verificada, listo para datos reales." << std::endl;
        return 0;
    }
}